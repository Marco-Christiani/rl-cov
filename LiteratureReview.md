# Literature Review
## Reading List
<details>
<summary>Expand Table</summary>
<table>
    <tr>
        <td>Topic</td>
        <td>Publication Year</td>
        <td>Author</td>
        <td>Title</td>
        <td>Publication Title</td>
        <td>DOI</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2019</td>
        <td>"Deshmukh, Samruddhi; Dubey, Amartansh"</td>
        <td>Improved Covariance Matrix Estimator using Shrinkage Transformation and Random Matrix Theory</td>
        <td></td>
        <td>10.48550/arXiv.1912.03718</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2004</td>
        <td>"Ledoit, Olivier; Wolf, Michael"</td>
        <td>A well-conditioned estimator for large-dimensional covariance matrices</td>
        <td>Journal of Multivariate Analysis</td>
        <td>10.1016/S0047-259X(03)00096-4</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2021</td>
        <td>"Bodnar, Taras; Parolya, Nestor; Thorsén, Erik"</td>
        <td>Dynamic Shrinkage Estimation of the High-Dimensional Minimum-Variance Portfolio</td>
        <td>IEEE Transactions on Signal Processing</td>
        <td>10.1109/TSP.2023.3263950</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2009</td>
        <td>"Ledoit, Olivier; P'ech'e, S."</td>
        <td>Eigenvectors of Some Large Sample Covariance Matrices Ensembles</td>
        <td></td>
        <td>10.2139/SSRN.1372052</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2004</td>
        <td>"Ledoit, Olivier; Wolf, Michael"</td>
        <td>"Honey, I shrunk the sample covariance matrix"</td>
        <td>The Journal of Portfolio Management</td>
        <td>10.3905/JPM.2004.110</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2022</td>
        <td>"Zhang, Yan; Tao, J.; Yin, Zhixiang; Wang, Guoqiang"</td>
        <td>Improved Large Covariance Matrix Estimation Based on Efficient Convex Combination and Its Application in Portfolio Optimization</td>
        <td>Mathematics</td>
        <td>10.3390/MATH10224282</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2019</td>
        <td>"Engle, Robert F.; Ledoit, Olivier; Wolf, Michael"</td>
        <td>Large Dynamic Covariance Matrices</td>
        <td>Journal of Business & Economic Statistics</td>
        <td>10.1080/07350015.2017.1345683</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2012</td>
        <td>"Ledoit, Olivier; Wolf, Michael"</td>
        <td>Nonlinear shrinkage estimation of large-dimensional covariance matrices</td>
        <td>arXiv: Statistics Theory</td>
        <td>10.1214/12-AOS989</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2017</td>
        <td>"Ledoit, Olivier; Wolf, Michael"</td>
        <td>Nonlinear Shrinkage of the Covariance Matrix for Portfolio Selection: Markowitz Meets Goldilocks</td>
        <td>Review of Financial Studies</td>
        <td>10.5167/UZH-90273</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2019</td>
        <td>"Benaych-Georges, F.; Bouchaud, J.; Potters, M."</td>
        <td>Optimal cleaning for singular values of cross-covariance matrices</td>
        <td>The Annals of Applied Probability</td>
        <td>10.1214/22-AAP1842</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2015</td>
        <td>"Wang, Cheng; Pan, Guangming; Tong, Tiejun; Zhu, Lixing"</td>
        <td>SHRINKAGE ESTIMATION OF LARGE DIMENSIONAL PRECISION MATRIX USING RANDOM MATRIX THEORY</td>
        <td>Statistica Sinica</td>
        <td>10.5705/SS.2012.328</td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2014</td>
        <td>"Ledoit, Olivier; Wolf, Michael"</td>
        <td>Spectrum Estimation: A Unified Framework for Covariance Matrix Estimation and PCA in Large Dimensions</td>
        <td>arXiv: Statistics Theory</td>
        <td></td>
    </tr>
    <tr>
        <td>Covariance Estimation</td>
        <td>2022</td>
        <td>"Lu, Cheng; Simaan, Majeed"</td>
        <td>Improved Estimation of the Covariance Matrix using Reinforcement Learning</td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>Generic PA</td>
        <td>2023</td>
        <td>"Lai, Zhao-Rong; Yang, Haisheng"</td>
        <td>A Survey on Gaps between Mean-Variance Approach and Exponential Growth Rate Approach for Portfolio Optimization</td>
        <td>ACM Computing Surveys</td>
        <td>10.1145/3485274</td>
    </tr>
    <tr>
        <td>Generic PA</td>
        <td>2016</td>
        <td>"Chopra, Vijay K.; Ziemba, William T."</td>
        <td>"The Effect of Errors in Means, Variances, and Covariances on Optimal Portfolio Choice"</td>
        <td>World Scientific handbook in financial economic series</td>
        <td>10.1142/9789813144385_0002</td>
    </tr>
    <tr>
        <td>Generic PA</td>
        <td>2021</td>
        <td>"Fan, Qingliang; Wu, Ruike; Yang, Yanrong; Zhong, Wei"</td>
        <td>Time-varying minimum variance portfolio</td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>RL for PA</td>
        <td>2018</td>
        <td>"Xiong, Zhuoran; Liu, Xiao-Yang; Zhong, Shan; Yang, Hongyang; Walid, Anwar"</td>
        <td>Practical Deep Reinforcement Learning Approach for Stock Trading</td>
        <td>"arXiv:1811.07522 [cs, q-fin, stat]"</td>
        <td></td>
    </tr>
    <tr>
        <td>RL for PA</td>
        <td>2020</td>
        <td>"Koker, Thomas E.; Koutmos, Dimitrios; Koutmos, Dimitrios"</td>
        <td>Cryptocurrency Trading Using Machine Learning</td>
        <td></td>
        <td>10.3390/jrfm13080178</td>
    </tr>
    <tr>
        <td>RL for PA</td>
        <td>2022</td>
        <td>"Aboussalah, Amine Mohamed; Xu, Ziyun; Lee, Chi-Guhn"</td>
        <td>What is the value of the cross-sectional approach to deep reinforcement learning?</td>
        <td><span style="color: red;">Quantitative Finance</span></td>
        <td>10.1080/14697688.2021.2001032</td>
    </tr>
    <tr>
        <td>RL for PA</td>
        <td>2023</td>
        <td>"Mattera, Giulio; Mattera, Raffaele"</td>
        <td>Shrinkage estimation with reinforcement learning of large variance matrices for portfolio selection</td>
        <td>Intelligent Systems with Applications</td>
        <td>10.1016/j.iswa.2023.200181</td>
    </tr>
    <tr>
        <td>RL for PA</td>
        <td>2021</td>
        <td>"Wu, Mu-En; Syu, Jia-Hao; Lin, Jerry Chun-Wei; Ho, Jan-Ming"</td>
        <td>Portfolio management system in equity market neutral using reinforcement learning</td>
        <td>Applied Intelligence</td>
        <td>10.1007/s10489-021-02262-0</td>
    </tr>
    <tr>
        <td>RL for PA</td>
        <td>2022</td>
        <td>"Lu, Cheng; Simaan, Majeed"</td>
        <td>Improved Estimation of the Covariance Matrix using Reinforcement Learning</td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>RL for PA</td>
        <td>2018</td>
        <td>"Li, Jinke; Rao, Ruonan; Shi, Jun"</td>
        <td>Learning to Trade with Deep Actor Critic Methods</td>
        <td></td>
        <td>10.1109/ISCID.2018.10116</td>
    </tr>
    <tr>
        <td>Supporting Material</td>
        <td>2016</td>
        <td>"Chopra, Vijay K.; Ziemba, William T."</td>
        <td>"The Effect of Errors in Means, Variances, and Covariances on Optimal Portfolio Choice"</td>
        <td>World Scientific handbook in financial economic series</td>
        <td>10.1142/9789813144385_0002</td>
    </tr>
    <tr>
        <td>Supporting Material</td>
        <td>2008</td>
        <td>"Ledoit, Olivier; Wolf, Michael"</td>
        <td>Robust Performance Hypothesis Testing with the Sharpe Ratio</td>
        <td><span style="color: red;">Journal of Empirical Finance</span></td>
        <td>10.1016/J.JEMPFIN.2008.03.002</td>
    </tr>
    <tr>
        <td>Supporting Material</td>
        <td>2007</td>
        <td>"Wierstra, Daan; Foerster, Alexander; Peters, Jan; Schmidhuber, Jürgen"</td>
        <td>Solving deep memory POMDPs with recurrent policy gradients</td>
        <td>Lecture Notes in Computer Science</td>
        <td>10.1007/978-3-540-74690-4_71</td>
    </tr>
    <tr>
        <td>Supporting Material</td>
        <td>2017</td>
        <td>"Liu, Weibo; Wang, Zidong; Liu, Xiaohui; Zeng, Nianyin; Liu, Yurong; Alsaadi, Fuad E."</td>
        <td>A survey of deep neural network architectures and their applications</td>
        <td>Neurocomputing</td>
        <td>10.1016/j.neucom.2016.12.038</td>
    </tr>
</table>
</details>

## Annotated items
<details>
<summary>
Ledoit, Olivier, and Michael Wolf. "Nonlinear Shrinkage of the Covariance Matrix for Portfolio Selection: Markowitz Meets Goldilocks." Review of Financial Studies, 2017. https://doi.org/10.5167/UZH-90273.
</summary>

**Methodology:** Authors develop a nonlinear shrinkage estimator for the covariance matrix that is tailored to Markowitz portfolio selection. The estimator has O(N) degrees of freedom and is proven to be asymptotically optimal.

**Network Architecture:** The paper does not involve deep learning or neural networks.

**Algorithms:** The authors derive an analytical formula for the optimal nonlinear shrinkage of the sample eigenvalues that minimizes the asymptotic limit of the portfolio loss function. For N dimensions we have N eigenvalues, thus N degrees of freedom.

**Training and Testing Data:** The method does not involve training data. It is evaluated on historical daily and monthly stock return data. The lookback window for estimation of the covariance matrix can be thought of as training data, in which case a variety are used in their robustness analysis.

**Evaluation Metrics and Criteria:** The proposed estimator is evaluated based on the out-of-sample standard deviation and Sharpe ratio of portfolio returns. A total of 11 approaches are compared.

**Results:** The nonlinear shrinkage estimator outperforms alternatives including linear shrinkage and sample covariance matrix in backtests.

**Conclusions:** The nonlinear shrinkage estimator with O(N) degrees of freedom is superior for portfolio selection compared to previous methods with O(1) or O(N^2) degrees of freedom.

**Limitations:** The method assumes no a priori knowledge about the orientation of the covariance matrix eigenvectors. Performance could potentially be further improved by incorporating such information.

**Suggestions for Future Work:** The authors suggest extending the nonlinear shrinkage approach to non-rotation equivariant situations and incorporating time-dependence in returns.
</details>

<details>
<summary>
Engle, Robert F., Olivier Ledoit, and Michael Wolf. "Large Dynamic Covariance Matrices." Journal of Business & Economic Statistics, 2019. https://doi.org/10.1080/07350015.2017.1345683.
</summary>

**Methodology:** Proposes combining two statistical methods - composite likelihood and nonlinear shrinkage - to improve estimation of the Dynamic Conditional Correlation (DCC) model for large covariance matrices.
</details>

<details>
<summary>
Mattera, Giulio, and Raffaele Mattera. "Shrinkage Estimation with Reinforcement Learning of Large Variance Matrices for Portfolio Selection." Intelligent Systems with Applications 17 (February 1, 2023): 200181. https://doi.org/10.1016/j.iswa.2023.200181.
</summary>

**Methodology:** Proposes a new shrinkage estimator for large covariance matrices based on deep reinforcement learning. The shrinkage intensity is optimized by a policy gradient agent to maximize the Sharpe ratio of the resulting minimum variance portfolio.

**Network Architecture:** Two architectures are used - a fully connected network for the Policy Gradient Agent (PGA) and a Gated Recurrent Unit (GRU) for the Recurrent Policy Gradient Agent (RPGA). The PGA has 3 hidden layers with 128, 64, and 8 nodes. The RPGA has 2 GRU layers with 256 and 128 nodes.  

**Algorithms:** Policy gradient algorithms are used to learn the optimal policy for selecting the shrinkage intensity. The PGA uses SGD with momentum while the RPGA uses Adam. The reward is the portfolio Sharpe ratio.

**Training and Testing Data:** 200 industry portfolio monthly returns from 1963-2022 (T=706 observations). Rolling window cross-validation is used with L=36 or 72 months for training and the rest for out-of-sample testing.

**Evaluation Metrics:** Out-of-sample Sharpe ratio and value-at-risk (VaR). Statistical tests are used to compare Sharpe ratios.

**Results:** The RPGA significantly outperforms existing methods, achieving a Sharpe ratio of 0.69 with L=36 vs 0.27-0.28 for others. It also has lower VaR. With L=72, RPGA Sharpe is 0.61 vs 0.28-0.33 for others.

**Conclusions:** The proposed RPGA shrinkage approach provides superior out-of-sample performance for minimum variance portfolios in high dimensions.

**Limitations:** 

**Future Work:** Apply the framework to other covariance-based analyses and datasets. Consider computational optimizations.
</details>

<details>
<summary>
Wu, Mu-En, Jia-Hao Syu, Jerry Chun-Wei Lin, and Jan-Ming Ho. "Portfolio Management System in Equity Market Neutral Using Reinforcement Learning." Applied Intelligence 51, no. 11 (November 1, 2021): 8119–31. https://doi.org/10.1007/s10489-021-02262-0.
</summary>

**RL Allocation Variant:** asset weight assignment

**Reward functions:** Return, Sharpe

**Performance metrics:** Return, Sharpe, MDD, Profit Factor

**Methodology:** Equity market neutral portfolio constructed by training one long and one short RL model.

**Features:** OHLC

**Network Architecture:** Two neural network architectures - a CNN and an RNN. The CNN uses convolutional layers, dense layers, and a softmax output layer. The RNN uses an LSTM layer followed by dense and softmax layers. Details like number of layers, neurons, etc are provided in Tables 1 and 2.    

**Algorithms:** No specifics. The CNN and RNN serving as the policy networks in the RL framework. The paper also proposes a novel reward function based on the Sharpe ratio.

**Train/Test Data:** The dataset consists of daily OHLC stock price data. The TW50 stock dataset from Aug 2015 - Jul 2017 is used for training, and Aug 2017 - Jul 2019 for testing.

**Evaluation Metrics:** Total return, Sharpe ratio, maximum drawdown, and profit factor are used to evaluate the performance.

**Results:** The proposed Sharpe ratio reward function outperforms the return-based reward, giving 39% higher returns and 13.7% lower drawdown. The CNN model outperforms RNN in returns and Sharpe ratio. The PMS outperforms benchmarks on TW50 and traditional stock datasets.

**Conclusions:** The PMS with CNN and novel Sharpe ratio reward is an effective portfolio management system with good profitability and low risk. It can support decision making for resource allocation in stock trading.

**Limitations:** Performance on the financial dataset was inferior to benchmarks.

**Future Work:** No concrete future work directions are suggested.
</details>

<details>
<summary>
Koker, Thomas E., Dimitrios Koutmos, and Dimitrios Koutmos. "Cryptocurrency Trading Using Machine Learning" 13, no. 8 (August 10, 2020): 178. https://doi.org/10.3390/jrfm13080178.
</summary>

**Methodology:** Direct reinforcement (DR) learning model to make trading decisions that optimize risk-adjusted returns

**Network Architecture:** No neural network architecture is used. The DR model is based on estimating parameters of a nonlinear autoregressive model.

**Algorithms:** The DR model uses gradient ascent to optimize the Sortino ratio as the reward function. No modifications to standard RL algorithms are mentioned.

**Training and Testing Data:** Cryptocurrency price data from August 2015 to August 2019 is used (1447 data points). The first 1000 days are used for training, then 100 day test windows are simulated.

**Evaluation Metrics:** Cumulative returns, Sharpe ratio, Sortino ratio, maximum drawdown, and value-at-risk.

**Results:** The DR model outperforms buy-and-hold for risk-adjusted returns in most cryptocurrencies tested. It also reduces maximum drawdown and value-at-risk in most cases.

**Conclusions:** The DR model demonstrates viability of active cryptocurrency trading and machine learning for superior performance compared to passive approaches.

**Limitations:** 

**Future Work:** Suggests integrating microstructure variables may further improve performance across more cryptocurrencies and market conditions.
</details>

<details>
<summary>
Xiong, Zhuoran, Xiao-Yang Liu, Shan Zhong, Hongyang Yang, and Anwar Walid. "Practical Deep Reinforcement Learning Approach for Stock Trading." arXiv:1811.07522 [Cs, q-Fin, Stat], December 1, 2018. http://arxiv.org/abs/1811.07522.
</summary>

**Methodology**: DDPG RL agent to make stock trading decisions.

**Network Architecture:**

**Algorithms:** DDPG. Reward is change in portfolio value.

**Training and Testing Data:** Used 6 years of daily stock price data (2009-2014) for 30 Dow Jones stocks for training, 1 year (2015) for validation, and 2.75 years (2016-2018) for testing.

**Evaluation Metrics and Criteria:** Annualized return, annualized standard error, final portfolio value, and Sharpe ratio.

**Results:** DDPG strategy achieved higher annualized return (22.24%), final portfolio value ($19,791), and Sharpe ratio (1.79) compared to Dow Jones Industrial Average and min-variance portfolio allocation baseline methods.

**Conclusions:** The DDPG agent was able to learn an effective trading strategy that outperformed the baselines in maximizing return while balancing risk.

**Limitations:** This method will underperform benchmarks such as Sharpe portfolio.

**Suggestions for Future Work:** "Future work will be interesting to explore more sophisticated model [20], deal with larger scale data [21], observe intelligent behaviors [22], and incorporate prediction schemes [23]"
</details>